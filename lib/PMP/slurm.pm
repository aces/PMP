###
# Package PMP::slurm - Poor Man's Pipeline using the Slurm batch system
#
# Very similar to the PBS module

package PMP::slurm;
use PMP::PMP;
use File::Temp qw/ tempdir /;
use MNI::MiscUtilities qw(shellquote);

@ISA = ("PMP::PMP");

use strict;

# set the submission command
sub setCommand {
    my $self = shift;
    my $Q = shift;
    $self->{slurmCommand} = $Q;
}

# set the batch queue
sub setQueue {
    my $self = shift;
    my $Q = shift;
    $self->{slurmQueue} = $Q;
}

# set the batch queue options
sub setQueueOptions {
    my $self = shift;
    my $opts = shift;

    $self->{slurmOpts} = $opts;
}

# set the batch hosts --- not supported in Slurm
sub setHosts {
    my $self = shift;
    my $hosts = shift;
    # $self->{slurmHosts} = $hosts;
    print "Warning: Host option $hosts ignored on Slurm\n";
}

# set the priority scheme --- not supported in Slurm
sub setPriorityScheme {
    my $self = shift;
    my $scheme = shift;

    print "Warning: Priority scheme $scheme ignored on Slurm\n";
    return;

    # only one allowed so far: later-stages, which give priority to
    # later stages over earlier stages.
    if (! $scheme =~ /later-stages/ ) {
        warn "Warning: illegal priority scheme $scheme. Ignoring request.\n";
    } else {
        # $self->{slurmPriorityScheme} = $scheme;
    }
}

# overwrite the execStage method and use Slurm qbatch command to submit jobs
sub execStage {
    my $self = shift;
    my $stageName = shift;

    # set the job name
    my $jobName = "$self->{NAME}-${stageName}";
    $jobName =~ s/;/_/g;
    $jobName =~ s/,/_/g;
    $jobName =~ s/\s/_/g;
    $jobName = "N$jobName" if ($jobName !~ /^[a-zA-Z]/);

    # run the stage in question
    $self->declareStageRunning($stageName);
    my $runningFile = $self->getRunningFile($stageName);

    # now set up the batch job
    my $logFile = $self->getLogFile($stageName);
    my $finishedFile = $self->getFinishedFile($stageName);
    my $failedFile = $self->getFailedFile($stageName);
    my $slurmSub = <<END;

#!/bin/sh
# generated by PMP::slurm
#SBATCH --job-name $jobName
#SBATCH --output $logFile

END

    # get the pipe queue
    if (exists $self->{slurmQueue}) {
        $slurmSub .= "#SBATCH --partition=$self->{slurmQueue}\n";
    }

#### NOT SUPPORTED ON SLURM????
#   # get the pipe hosts
#   if (exists $self->{slurmHosts}) {
#       $slurmSub .= "#\$ -l host=$self->{slurmHosts}\n";
#   }

#   if (exists $self->{slurmPriorityScheme}) {
#       # error check for an admittedly unlikely condition
#       unless ($self->{STAGES}{$stageName}{'order'} > 1024 ||
#               $self->{STAGES}{$stageName}{'order'} < -1023) {
#           $slurmSub .= "#\$ -p $self->{STAGES}{$stageName}{'order'}\n";
#       }
#   }

    $slurmSub .= "cd \$SLURM_SUBMIT_DIR\n";

    # now add the environment to the submission command
    # don't include vars with () in them and remove '\n' inside names (CL).
    foreach my $env ( keys %ENV ) {
        if( !( ${env} =~ m/\(\)/ ) ) {
            my $val = $ENV{$env};
            $val =~ s/\n//g;
            $slurmSub .= "export ${env}=\"${val}\"\n";
        }
    }

    # define the command string
    my $cmdstring = shellquote(@{ $self->{STAGES}{$stageName}{'args'} });

    $slurmSub .= <<END;

echo "Start running on: " `uname -s -n -r` " at " `date`
echo "$cmdstring"
$cmdstring
if test "\$?" -eq "0"
#if [ "\$?" == "0" ] ## broken on Ubuntu Hardy and up.
then
  touch $finishedFile
else
  touch $failedFile
fi

rm -f $runningFile

END

#open PIPE, ">/tmp/claude/test.sh";
#print PIPE $slurmSub;
#close PIPE;
    if (! (exists $self->{slurmCommand}) ) {
      $self->{slurmCommand} = "sbatch";
    }

    my $pipeCmd = "|$self->{slurmCommand} ";
    if (exists $self->{slurmOpts}) {
      $pipeCmd .= " $self->{slurmOpts}";
    }
    if ($self->{STAGES}{$stageName}{'slurm_opts'}) {
      $pipeCmd .= " $self->{STAGES}{$stageName}{'slurm_opts'}";
    }
    if( open PIPE, $pipeCmd) {
      print PIPE $slurmSub;
      if (! close PIPE ) {
        warn "ERROR: could not close $self->{slurmCommand} pipe $self->{NAME}: $!\n";
        warn "Continuing for now, but this pipe might have gone bad.\n";
      }
    } else {
      `touch $failedFile`;
      unlink $runningFile;
      warn "ERROR: could not open pipe to $self->{slurmCommand}: $!\n";
    }

}


# use Slurm qbatch command to submit all jobs at once

sub execAllStages {
    my $self = shift;

    # set the job name
    my $jobName = "$self->{NAME}";
    $jobName =~ s/;/_/g;
    $jobName =~ s/,/_/g;
    $jobName =~ s/\s/_/g;
    $jobName = "N$jobName" if ($jobName !~ /^[a-zA-Z]/);
    my $jobLogFile = $self->getLogFile("");

    my $slurmSub = <<END;    # don't put a blank line here
#!/bin/sh
# generated by PMP::slurm
#SBATCH --job-name $jobName
#SBATCH --output $jobLogFile
END

    # get the pipe queue
    if (exists $self->{slurmQueue}) {
        $slurmSub .= "#SBATCH --partition=$self->{slurmQueue}\n";
    }

    $slurmSub .= "cd \$SLURM_SUBMIT_DIR\n";

    # now add the environment to the submission command
    # don't include vars with () in them and remove '\n' inside names (CL).
    foreach my $env ( keys %ENV ) {
        if( !( ${env} =~ m/\(\)/ ) ) {
            my $val = $ENV{$env};
            $val =~ s/\n//g;
            $slurmSub .= "export ${env}=\"${val}\"\n";
        }
    }

    $slurmSub .= <<END;
END

    # write out the stages

#### NOT SUPPORTED ON SLURM????
    # $self->sortStages() unless $self->{isSorted};

    foreach my $stage ( @{ $self->{sortedStages} } ) {

      # check to make sure that this stage is in the subset of stages to be run

      if ( ( ! $self->{STAGES}{$stage}{'finished'} ) &&
           ( $self->{runAllStages} == 1 || $self->{stagesSubset}{$stage} ) ) {

        # run the stage in question
        $self->declareStageRunning($stage);
        my $runningFile = $self->getRunningFile($stage);

        my $logFile = $self->getLogFile($stage);
        my $finishedFile = $self->getFinishedFile($stage);
        my $failedFile = $self->getFailedFile($stage);

        # define the command string
        my $cmdstring = shellquote(@{ $self->{STAGES}{$stage}{'args'} });

        # now set up the shell script for the batch job
        $slurmSub .= <<END;
echo "Start running on: " `uname -s -n -r` " at " `date` \>\& $logFile
echo "$cmdstring" \>\> $logFile 2\>\&1
$cmdstring \>\> $logFile 2\>\&1
if [ "\$?" == "0" ]
then
  touch $finishedFile
else
  touch $failedFile
  rm -f $runningFile
  exit 1
fi
rm -f $runningFile
END
      }
    }

open PIPE, ">/tmp/claude_test.sh";
print PIPE $slurmSub;
close PIPE;

    # Submit the job this way to avoid the 100k command line
    # limit in sh if commands are piped to qbatch. Using a file
    # removes the size restriction on the job script.

    my $tmpdir = &tempdir( "pmp-XXXXXXXX", TMPDIR => 1, CLEANUP => 1 );
    my $job_script = "${tmpdir}/${jobName}.sh";
    open PIPE, ">${job_script}";
    print PIPE $slurmSub;
    close PIPE;

    if (! (exists $self->{slurmCommand}) ) {
      $self->{slurmCommand} = "qbatch";
    }

    my $pipeCmd = "|$self->{slurmCommand} ";
    if (exists $self->{slurmOpts}) {
      $pipeCmd .= " $self->{slurmOpts}";
    }
    $pipeCmd .= " $job_script";

    if( open PIPE, $pipeCmd) {
      if (! close PIPE ) {
        warn "ERROR: could not close $self->{slurmCommand} pipe $self->{NAME}: $!\n";
        warn "Continuing for now, but this pipe might have gone bad.\n";
        unlink( $job_script );
      }
    }
}


1;
